# Анализ защищенности систем искусственного интеллекта

- [Практическое задание №1](./prz1/) - Установка окружения и настройка фреймворков для анализа защищенности ИИ
- [Практическое задание №2](./prz2/) - Исследование атак на модели ИИ. Fast Gradient Sign Method (FGSM)
- [Практическое задание №3](./prz3/) - Атака Carlini-Wagner (CW) на модели ИИ
- [Практическое задание №4](./prz4/) - Атака DeepFool на модели ИИ
- [Практическое задание №5](./prz5/) - Атака с ограниченной памятью (PGD -
Projected Gradient Descent)
- [Практическое задание №6](./prz6/) - Атака по переносу (Transfer Attack) на модели ИИ
- [Практическое задание №7](./prz7/) - Создание и использование генеративных противоречивых примеров (GAN-based Adversarial Examples)
- [Практическое задание №8](./prz8/) - Методы защиты от атак на модели ИИ
- [Лабораторная работа №1](./lab1/)
- [Лабораторная работа №2](./lab2/)
- [Лабораторная работа №3](./lab3/)